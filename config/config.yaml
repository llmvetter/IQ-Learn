gamma: 0.98
seed: 42

train:
  batch_size: 256
  epochs: 200 #number of epochs
  episodes: 300 #number of environemnt episodes per epoch
  sampling_steps: 100 #number of environment sampling steps per episode
  learn_steps: 20000

env:
  name: CarFollowing
  max_v: 40 # in m/s
  max_g: 150 # in m
  max_rel_v: 30
  delta_t: 0.3
  policy_memory: 2000
  expert_memory: 10000

method:
  type: iq
  loss: value
  tanh: False
  regularize: True
  div: chi
  alpha: 3

agent:
  name: softq
  class: agent.softq.SoftQ
  obs_dim: 0 # To be updated after loading the environment
  action_dim: 0 # To be updated after loading the environment
  critic_cfg:
    _target_: agent.softq_models.SimpleQNetwork
    obs_dim: 0
    action_dim: 0
  critic_lr: 5e-5
  critic_betas: [0.9, 0.999]
  init_temp: 0.1
  target_update_frequency: 1 # 1 equals soft update, >1 for hard updates
  tau: 0.01 # Percentage of parameters to copy q_net into target, tau=1 equals hard update

q_net:
  _target_: agent.softq_models.SimpleQNetwork
  obs_dim: ${agent.obs_dim}
  action_dim: ${agent.action_dim}
