exp_name: ""
project_name: ${env.name}

cuda_deterministic: False
device: cpu

gamma: 0.99
seed: 0
pretrain: null

num_seed_steps: 0 # Don't need seeding for IL (Use 1000 for RL)
only_expert_states: False

train:
  batch: 32
  use_target: False
  soft_update: False

expert:
  demos: 1
  subsample_freq: 1

eval:
  policy: null
  threshold: null
  use_baselines: False
  eps: 10
  transfer: False
  expert_env: ""

env:
  name: CarFollowingEnv
  replay_mem: 50000
  initial_mem: 1280
  eps_steps: 1000
  eps_window: 100
  learn_steps: 5e5
  eval_interval: 5e3

method:
  type: iq

agent:
  name: softq
  class: agent.softq.SoftQ
  obs_dim: 0 # To be updated after loading the environment
  action_dim: 0 # To be updated after loading the environment
  critic_cfg:
    _target_: agent.softq_models.OfflineQNetwork
  critic_lr: 1e-4
  critic_betas: [0.9, 0.999]
  init_temp: 0.01
  critic_target_update_frequency: 4
  critic_tau: 0.1

q_net:
  _target_: agent.softq_models.SimpleQNetwork
  obs_dim: ${agent.obs_dim}
  action_dim: ${agent.action_dim}
